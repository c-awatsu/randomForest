{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ca/PycharmProjects/JupyterNoteBookExample/venv/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n  \"\"\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.io.sql as psql\n",
    "import psycopg2 as pg\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.engine.saving import model_from_json\n",
    "from keras.layers import SimpleRNN, Activation\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pg.connect(database='chi-navi',\n",
    "                host='localhost',\n",
    "                user='postgres',\n",
    "                port=5432) as conn:\n",
    "    all_season_sql = \\\n",
    "        \"with spot_bus_stop as( \" \\\n",
    "        \"select \" \\\n",
    "        \"p.bus_stop_id,s.spot_id \" \\\n",
    "        \"from \" \\\n",
    "        \"(select bus_stop_id,latlon::point as latlon from bus_stop) as p, \" \\\n",
    "        \"spot s \" \\\n",
    "        \"where \" \\\n",
    "        \"ST_Covers( \" \\\n",
    "        \"ST_Buffer( \" \\\n",
    "        \"ST_POINT(s.area[0], s.area[1])::geography,400), \" \\\n",
    "        \"ST_POINT(p.latlon[1], p.latlon[0]) \" \\\n",
    "        \") \" \\\n",
    "        \"), \" \\\n",
    "        \"delay_info as( \" \\\n",
    "        \"with route_bus_stop_list as( \" \\\n",
    "        \"select \" \\\n",
    "        \"t.task_id,r.route_id,b.bus_stop_id,rbs.ordinal \" \\\n",
    "        \"from \" \\\n",
    "        \"bus_stop b,route r,route_bus_stop rbs,task t \" \\\n",
    "        \"where \" \\\n",
    "        \"b.bus_stop_id = rbs.bus_stop_id \" \\\n",
    "        \"and r.route_id = rbs.route_id \" \\\n",
    "        \"and t.route_id = r.route_id \" \\\n",
    "        \"order by r.route_id,rbs.ordinal \" \\\n",
    "        \"), \" \\\n",
    "        \"delay_list as( \" \\\n",
    "        \"with stddev as( \" \\\n",
    "        \"select \" \\\n",
    "        \"stddev_samp(extract(epoch from (collide_at - departure_time))) as stddev \" \\\n",
    "        \"from \" \\\n",
    "        \"task_delay \" \\\n",
    "        \"where \" \\\n",
    "        \"(collide_at - departure_time) > '00:00:00' \" \\\n",
    "        \"), \" \\\n",
    "        \"delay_avg as( \" \\\n",
    "        \"select \" \\\n",
    "        \"avg((extract(epoch from (collide_at - departure_time)))) as delay_avg \" \\\n",
    "        \"from \" \\\n",
    "        \"task_delay \" \\\n",
    "        \"where \" \\\n",
    "        \"(collide_at - departure_time) > '00:00:00' \" \\\n",
    "        \") \" \\\n",
    "        \"select \" \\\n",
    "        \"td.task_id,td.departure_time,td.bus_stop_id,td.submit_in,td.collide_at \" \\\n",
    "        \",extract(epoch from (td.collide_at - td2.departure_time)) as delay \" \\\n",
    "        \"from \" \\\n",
    "        \"task_delay td,delay_avg da,stddev std,task_detail td2 \" \\\n",
    "        \"where \" \\\n",
    "        \"(extract(epoch from (td.collide_at - td2.departure_time)) between \" \\\n",
    "        \"da.delay_avg - std.stddev * 3 and da.delay_avg + std.stddev * 3) \" \\\n",
    "        \"and extract(epoch from (td.collide_at - td2.departure_time)) > 0 \" \\\n",
    "        \"and td.task_id = td2.task_id \" \\\n",
    "        \"and td.bus_stop_id = td2.bus_stop_id \" \\\n",
    "        \"and td.departure_time = td2.departure_time \" \\\n",
    "        \") \" \\\n",
    "        \"select \" \\\n",
    "        \"distinct r.route_id,r.bus_stop_id,r.ordinal,d.collide_at, \" \\\n",
    "        \"d.task_id,d.delay,d.submit_in,d.departure_time,date_part('HOUR' , d.departure_time) as time \" \\\n",
    "        \"from \" \\\n",
    "        \"delay_list d, route_bus_stop_list r \" \\\n",
    "        \"where \" \\\n",
    "        \"d.bus_stop_id = r.bus_stop_id \" \\\n",
    "        \"and r.task_id = d.task_id \" \\\n",
    "        \"), \" \\\n",
    "        \"access_info as( \" \\\n",
    "        \"select \" \\\n",
    "        \"count(distinct session_id) as access_num,browsing_at::date as date, \" \\\n",
    "        \"date_part('HOUR' , browsing_at) as time, \" \\\n",
    "        \"case when \" \\\n",
    "        \"extract(dow from browsing_at::date) = 0 or extract(dow from browsing_at::date) = 6 then 0 \" \\\n",
    "        \"else 1 \" \\\n",
    "        \"end as youbi \" \\\n",
    "        \"from \" \\\n",
    "        \"user_browsing_log ubl \" \\\n",
    "        \"group by date,time \" \\\n",
    "        \") \" \\\n",
    "        \"select \" \\\n",
    "        \"case \" \\\n",
    "        \"when delay between 0 and 60 then 0 \" \\\n",
    "        \"when delay between 61 and 120 then 1 \" \\\n",
    "        \"when delay between 121 and 180 then 2 \" \\\n",
    "        \"when delay between 181 and 240 then 3 \" \\\n",
    "        \"when delay between 241 and 300 then 4 \" \\\n",
    "        \"when delay between 301 and 360 then 5 \" \\\n",
    "        \"when delay between 361 and 420 then 6 \" \\\n",
    "        \"when delay between 421 and 480 then 7 \" \\\n",
    "        \"when delay between 481 and 540 then 8 \" \\\n",
    "        \"when delay > 540 then 9 \" \\\n",
    "        \"end as delay, \" \\\n",
    "        \"ai.time, \" \\\n",
    "        \"ai.access_num,ai.youbi, \" \\\n",
    "        \"case \" \\\n",
    "        \"when submit_in = '2017-07-23' then 1 /* 航空祭 */  \" \\\n",
    "        \"when (submit_in between '2018-01-26' and '2018-02-18') or \" \\\n",
    "        \"(submit_in between '2017-01-27' and '2017-02-19') \" \\\n",
    "        \"then 2/* ひょうとう祭り */ \" \\\n",
    "        \"when submit_in between '2017-07-06' and '2017-07-09' then 3/* セガサミーカップ */ \" \\\n",
    "        \"else 0 \" \\\n",
    "        \"end as event, \" \\\n",
    "        \"case \" \\\n",
    "        \"when di.route_id in (13,14,23,24,55,56,58,59,60,61,62,63,64,67,68,69,70,71,74 \" \\\n",
    "        \",78,79,80,81,82,91,92,93,94,95,96,97,98,99,106,107,108,109,11) \" \\\n",
    "        \"then 1 \" \\\n",
    "        \"else 0 \" \\\n",
    "        \"end as destination, \" \\\n",
    "        \"di.bus_stop_id, \" \\\n",
    "        \"s.spot_id \" \\\n",
    "        \"from \" \\\n",
    "        \"spot_bus_stop s, \" \\\n",
    "        \"delay_info di, \" \\\n",
    "        \"access_info ai \" \\\n",
    "        \"where \" \\\n",
    "        \"di.time = ai.time \" \\\n",
    "        \"and di.submit_in = ai.date \" \\\n",
    "        \"and s.bus_stop_id = di.bus_stop_id \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_result = psql.read_sql(all_season_sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3030004\n"
     ]
    }
   ],
   "source": [
    "maxLen = 100\n",
    "length_of_sequence = 2 * len(sql_result)\n",
    "X = np.zeros((len(sql_result), maxLen, 1), dtype=float)\n",
    "Y = np.zeros((len(sql_result), 1), dtype=float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_train = int(len(sql_result) * 0.9)\n",
    "N_validation = len(sql_result) - N_train\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "    model_selection.train_test_split(X, Y, test_size=N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(units=4, kernel_initializer='he_normal', input_shape=(maxLen, 5)))\n",
    "model.add(Dense(4, kernel_initializer='he_normal'))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 10\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(X_validation, Y_validation),\n",
    "          callbacks=[EarlyStopping(monitor='loss', patience=10, verbose=1)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
